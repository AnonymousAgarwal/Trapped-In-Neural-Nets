{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RksWtNuHg9Rb"
      },
      "source": [
        "# Assignment\n",
        "*  In this assignment, we will build a classifier for MNIST from scratch using just [NumPy](https://numpy.org/)\n",
        "\n",
        "*  [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains images of handwritten digits of size 28x28\n",
        "\n",
        "*  The dataset that you are expected to use for training is already uploaded along\n",
        "\n",
        "*   Our model will have 1 hidden layer, like the one below (not our recommendation to use 256 in the hidden layer though, try various values out)\n",
        "\n",
        "**Feel free to redefine any function signatures below, just make sure the final cell remains the same.**\n",
        "\n",
        "<center>\n",
        "<img src=\"https://user-images.githubusercontent.com/81357954/166119893-4ca347b8-b1a4-40b8-9e0a-2e92b5f164ae.png\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyOAG55siwdI"
      },
      "source": [
        "## Import libraries here\n",
        "NumPy, Matplotlib, ...\n",
        "\n",
        "Also remember to initialize the seed for reproducibility of results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iVUsRLxjAb9"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaLDC4wN0eQs"
      },
      "source": [
        "## Load *Dataset*\n",
        "Load data from the given pickle file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qOjNSmx0iUn"
      },
      "outputs": [],
      "source": [
        "\n",
        "data_file=\"MNIST_data.pkl\"\n",
        "# load the data set\n",
        "with open(data_file,'rb') as infile:\n",
        "    train_dataset = pickle.load(infile)\n",
        "X = train_dataset['X']\n",
        "y = train_dataset['y']\n",
        "\n",
        "# normalize\n",
        "\n",
        "# Split into X_train, y_train, X_test, y_test\n",
        "# you can use stratified splitting from sklearn library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id77Oqc90kTf"
      },
      "outputs": [],
      "source": [
        "# display a 4x4 grid, \n",
        "# choose 16 images randomly, display the images as well as corresponding labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFYnsPVLmsiW"
      },
      "source": [
        "## Building up parts of our classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAsGtgxUpGh2"
      },
      "source": [
        "**Activation functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Di5Ck47msCQ"
      },
      "outputs": [],
      "source": [
        "def relu(z):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    z -- A scalar or numpy array.\n",
        "    Return:\n",
        "    relu func applied to each element of z\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "def softmax(z):\n",
        "    \"\"\"\n",
        "    returns computed probabilitites for each element in batch separately\n",
        "    input: (N, 10)\n",
        "    output: (N, 10)\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-q5HJHIocdn"
      },
      "source": [
        "**Notes about the Neural Network** \n",
        "*   Input size is (784,) because 28x28 = 784\n",
        "*   Output size will be 10, each element represeting probability of the image representing that digit\n",
        "*   Size of the hidden layer is a hyperparameter\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azTAuS5spFcz"
      },
      "source": [
        "**Initialize the layers weights**\n",
        "\n",
        "Generally, we follow the convention that weights are drawn from a standard normal distribution, while the bias vectors are initialized to zero. But you can try everything out :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38E3_hVPocMm"
      },
      "outputs": [],
      "source": [
        "def init_params(\"\"\"TO DO\"\"\"):\n",
        "    \"\"\"\n",
        "    ideally it should take the size of all the layers and \n",
        "    should return the initialized weights.\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlX8zy-7pv2n"
      },
      "source": [
        "**Forward Propagation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ8lgrqjjASz"
      },
      "outputs": [],
      "source": [
        "def forward_propg(X, weights):\n",
        "    \"\"\"\n",
        "    X: input data\n",
        "    returns: logits, output of each layer z1,z2,a1,a2\n",
        "    \"\"\"\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asZmbRVvuy5x"
      },
      "source": [
        "**Backward Propagation**\n",
        "\n",
        "\n",
        "You may use stochastic gradient descent or batch gradient descent here. Feel free to use any loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAmrTAlimjUN"
      },
      "outputs": [],
      "source": [
        "def backward_propg(weights, X, y, \"\"\"output of forward propg\"\"\"):\n",
        "    \"\"\"\n",
        "    should update the weights and return updated weights\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVDz0IGnvzpe"
      },
      "outputs": [],
      "source": [
        "def cost_func(weight,y,params):\n",
        "    \"\"\"\n",
        "    calculate loss to check whether it is decreasing at each epoch or not\n",
        "    one can return this in backward propagation as well\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUlhpcs9ylOX"
      },
      "source": [
        "\n",
        "## Integrate everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDGdT7PVmjRU"
      },
      "outputs": [],
      "source": [
        "def train(X, y, hidden_nodes, epochs=1000, lr=1e-5):\n",
        "    \"\"\"\n",
        "    hidden_nodes: no. of nodes in hidden layer\n",
        "\n",
        "    should return the updated optimize weights.\n",
        "    \"\"\"\n",
        "    # initialize weights.\n",
        "\n",
        "    for i in range(epochs):\n",
        "        # forward propagation\n",
        "\n",
        "        # print cost at every 100 or so iterations\n",
        "        \n",
        "        # backward propagation\n",
        "        \n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XBinWpPmjOS"
      },
      "outputs": [],
      "source": [
        "def predict(X, updated_weights):\n",
        "    \"\"\"\n",
        "    returns the prediction in [0,9] for each element in X\n",
        "    \"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtKSZWw71wc4"
      },
      "outputs": [],
      "source": [
        "def accuracy(predictions, y):\n",
        "    \"\"\"\n",
        "    prints % accuracy\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGVOZ8yg0VrV"
      },
      "source": [
        "### Save as pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_lvDVwmxmjKX",
        "outputId": "02467c3f-b20f-44b7-8e3d-43e308028d17"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import random\n",
        "\n",
        "roll_num = \"_________\" # enter ldap\n",
        "hidden_dim = pass # replace with your own hidden dimension\n",
        "\n",
        "model_dict = {\n",
        "    'z': hidden_dim, # hidden dimension of your model\n",
        "    'layer_0_wt': pass, # layer 0 weight (784, z)\n",
        "    'layer_0_bias': pass, # layer 0 bias (z, 1)\n",
        "    'layer_1_wt': pass, # layer 1 weight (z, 10)\n",
        "    'layer_1_bias': pass # layer 1 bias (10, 1)\n",
        "}\n",
        "\n",
        "assert model_dict['layer_0_wt'].shape == (784, hidden_dim)\n",
        "assert model_dict['layer_0_bias'].shape == (hidden_dim, 1)\n",
        "assert model_dict['layer_1_wt'].shape == (hidden_dim, 10)\n",
        "assert model_dict['layer_1_bias'].shape == (10, 1)\n",
        "\n",
        "with open(f'model_{roll_num}.pkl', 'wb') as f:\n",
        "    pickle.dump(model_dict, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment1_Problem_Statement.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
